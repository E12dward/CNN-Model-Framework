{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import os  \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, Dense, BatchNormalization, Activation\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, add\n",
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D\n",
    "\n",
    "from keras import optimizers,regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import he_normal\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "\n",
    "num_classes        = 10\n",
    "batch_size         = 64         # 64 or 32 or other\n",
    "epochs             = 300\n",
    "iterations         = 782       \n",
    "weight_decay=1e-4\n",
    "\n",
    "log_filepath  = './xception_he_wd_slim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_preprocessing(x_train,x_test):\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    mean = [125.307, 122.95, 113.865]\n",
    "    std  = [62.9932, 62.0887, 66.7048]\n",
    "    for i in range(3):\n",
    "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "    return x_train, x_test\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 100:\n",
    "        return 0.01\n",
    "    if epoch < 200:\n",
    "        return 0.001\n",
    "    return 0.0001\n",
    "\n",
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train, x_test = color_preprocessing(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 36 convolutional layers are structured into 14 modules\n",
    "def entryflow(x,params,top=False,last=False):\n",
    "    # modules 2-4,13\n",
    "    # params is (3,)\n",
    "    # top = true means module 2, don't use relu\n",
    "    if last:\n",
    "        stride = (2,2)\n",
    "    else:\n",
    "        stride = (1,1)\n",
    "    residual = Conv2D(params[0], (1, 1), strides=stride,padding='same',\n",
    "                     kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    residual = BatchNormalization(momentum=0.9, epsilon=1e-5)(residual)\n",
    "    if top:\n",
    "        x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params[1], (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params[2], (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=stride,padding='same')(x)\n",
    "    x = add([x, residual])\n",
    "    return x\n",
    "    \n",
    "def middleflow(x,params):\n",
    "    # modules 5-12, params is int\n",
    "    residual = x\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params, (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params, (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params, (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = add([x, residual])\n",
    "    return x\n",
    "\n",
    "def exitflow(x,params):\n",
    "    # modules 14 , params is (2,)\n",
    "    x = SeparableConv2D(params[0], (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(params[1], (3, 3),padding='same',\n",
    "                       depthwise_initializer=\"he_normal\",\n",
    "                       pointwise_initializer=\"he_normal\",\n",
    "                       depthwise_regularizer=regularizers.l2(weight_decay),\n",
    "                       pointwise_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xception(img_input,shallow=False, classes=10):\n",
    "    # modules 1\n",
    "    x = Conv2D(32,(3, 3),strides=(2, 2),padding='same',\n",
    "              kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay))(img_input)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3),strides=(1,1),padding='same',\n",
    "              kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # module 2\n",
    "    x = entryflow(x,(128,128,128),top=True)\n",
    "    # module 3-4\n",
    "    x = entryflow(x,(256,256,256))\n",
    "    x = entryflow(x,(728,728,728))\n",
    "    # module 5-12\n",
    "    for _ in range(8):\n",
    "        x = middleflow(x,728)\n",
    "    # module 13\n",
    "    x = entryflow(x,(1024,728,1024),last=True)\n",
    "    # module 14\n",
    "    x = exitflow(x,(1536,2048))\n",
    "    # output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input=Input(shape=(32,32,3))\n",
    "output = xception(img_input)\n",
    "model=Model(img_input,output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "782/782 [==============================] - 322s 412ms/step - loss: 5.6460 - acc: 0.4680 - val_loss: 5.3964 - val_acc: 0.5563\n",
      "Epoch 2/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 5.1249 - acc: 0.6190 - val_loss: 4.9695 - val_acc: 0.6538\n",
      "Epoch 3/300\n",
      "782/782 [==============================] - 312s 398ms/step - loss: 4.8282 - acc: 0.6864 - val_loss: 4.8095 - val_acc: 0.6810\n",
      "Epoch 4/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 4.5991 - acc: 0.7283 - val_loss: 4.6109 - val_acc: 0.7115\n",
      "Epoch 5/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 4.4042 - acc: 0.7577 - val_loss: 4.3459 - val_acc: 0.7615\n",
      "Epoch 6/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 4.2309 - acc: 0.7819 - val_loss: 4.2580 - val_acc: 0.7669\n",
      "Epoch 7/300\n",
      "782/782 [==============================] - 312s 398ms/step - loss: 4.0793 - acc: 0.7956 - val_loss: 4.0715 - val_acc: 0.7910\n",
      "Epoch 8/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.9347 - acc: 0.8125 - val_loss: 3.9678 - val_acc: 0.7915\n",
      "Epoch 9/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.7989 - acc: 0.8255 - val_loss: 3.7845 - val_acc: 0.8241\n",
      "Epoch 10/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.6813 - acc: 0.8337 - val_loss: 3.7084 - val_acc: 0.8155\n",
      "Epoch 11/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.5515 - acc: 0.8463 - val_loss: 3.6358 - val_acc: 0.8176\n",
      "Epoch 12/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 3.4321 - acc: 0.8578 - val_loss: 3.7288 - val_acc: 0.7772\n",
      "Epoch 13/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.3287 - acc: 0.8626 - val_loss: 3.4350 - val_acc: 0.8301\n",
      "Epoch 14/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 3.2237 - acc: 0.8716 - val_loss: 3.2913 - val_acc: 0.8457\n",
      "Epoch 15/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 3.1203 - acc: 0.8787 - val_loss: 3.2959 - val_acc: 0.8208\n",
      "Epoch 16/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 3.0202 - acc: 0.8847 - val_loss: 3.2076 - val_acc: 0.8298\n",
      "Epoch 17/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 2.9290 - acc: 0.8916 - val_loss: 3.0716 - val_acc: 0.8433\n",
      "Epoch 18/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 2.8315 - acc: 0.8992 - val_loss: 3.0578 - val_acc: 0.8348\n",
      "Epoch 19/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 2.7501 - acc: 0.9034 - val_loss: 2.9409 - val_acc: 0.8505\n",
      "Epoch 20/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 2.6682 - acc: 0.9089 - val_loss: 2.8607 - val_acc: 0.8498\n",
      "Epoch 21/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 2.5891 - acc: 0.9117 - val_loss: 2.7869 - val_acc: 0.8526\n",
      "Epoch 22/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 2.5097 - acc: 0.9161 - val_loss: 2.7338 - val_acc: 0.8556\n",
      "Epoch 23/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 2.4420 - acc: 0.9186 - val_loss: 2.6692 - val_acc: 0.8566\n",
      "Epoch 24/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 2.3687 - acc: 0.9252 - val_loss: 2.6078 - val_acc: 0.8586\n",
      "Epoch 25/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 2.3110 - acc: 0.9250 - val_loss: 2.5800 - val_acc: 0.8546\n",
      "Epoch 26/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 2.2338 - acc: 0.9308 - val_loss: 2.4714 - val_acc: 0.8676\n",
      "Epoch 27/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 2.1645 - acc: 0.9355 - val_loss: 2.4389 - val_acc: 0.8656\n",
      "Epoch 28/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 2.1111 - acc: 0.9366 - val_loss: 2.3433 - val_acc: 0.8732\n",
      "Epoch 29/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 2.0515 - acc: 0.9381 - val_loss: 2.3594 - val_acc: 0.8590\n",
      "Epoch 30/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.9942 - acc: 0.9404 - val_loss: 2.2827 - val_acc: 0.8665\n",
      "Epoch 31/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.9355 - acc: 0.9442 - val_loss: 2.2991 - val_acc: 0.8596\n",
      "Epoch 32/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.8838 - acc: 0.9462 - val_loss: 2.2120 - val_acc: 0.8656\n",
      "Epoch 33/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.8343 - acc: 0.9471 - val_loss: 2.1731 - val_acc: 0.8658\n",
      "Epoch 34/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.7937 - acc: 0.9475 - val_loss: 2.1813 - val_acc: 0.8596\n",
      "Epoch 35/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.7296 - acc: 0.9551 - val_loss: 2.0921 - val_acc: 0.8701\n",
      "Epoch 36/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.6958 - acc: 0.9526 - val_loss: 2.0446 - val_acc: 0.8762\n",
      "Epoch 37/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.6461 - acc: 0.9546 - val_loss: 2.0072 - val_acc: 0.8659\n",
      "Epoch 38/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.5965 - acc: 0.9585 - val_loss: 1.9396 - val_acc: 0.8757\n",
      "Epoch 39/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.5676 - acc: 0.9554 - val_loss: 1.9940 - val_acc: 0.8588\n",
      "Epoch 40/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.5261 - acc: 0.9566 - val_loss: 1.9029 - val_acc: 0.8700\n",
      "Epoch 41/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.4807 - acc: 0.9595 - val_loss: 1.8812 - val_acc: 0.8693\n",
      "Epoch 42/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.4432 - acc: 0.9617 - val_loss: 1.7739 - val_acc: 0.8832\n",
      "Epoch 43/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.4083 - acc: 0.9616 - val_loss: 1.8580 - val_acc: 0.8608\n",
      "Epoch 44/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.3784 - acc: 0.9613 - val_loss: 1.7960 - val_acc: 0.8663\n",
      "Epoch 45/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 1.3488 - acc: 0.9618 - val_loss: 1.7182 - val_acc: 0.8770\n",
      "Epoch 46/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.3110 - acc: 0.9628 - val_loss: 1.6819 - val_acc: 0.8794\n",
      "Epoch 47/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.2718 - acc: 0.9673 - val_loss: 1.7070 - val_acc: 0.8749\n",
      "Epoch 48/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.2467 - acc: 0.9654 - val_loss: 1.7113 - val_acc: 0.8689\n",
      "Epoch 49/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.2285 - acc: 0.9622 - val_loss: 1.6361 - val_acc: 0.8721\n",
      "Epoch 50/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.1917 - acc: 0.9659 - val_loss: 1.5608 - val_acc: 0.8835\n",
      "Epoch 51/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 1.1648 - acc: 0.9652 - val_loss: 1.5596 - val_acc: 0.8798\n",
      "Epoch 52/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.1274 - acc: 0.9693 - val_loss: 1.5421 - val_acc: 0.8827\n",
      "Epoch 53/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.1054 - acc: 0.9688 - val_loss: 1.4725 - val_acc: 0.8853\n",
      "Epoch 54/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.0803 - acc: 0.9694 - val_loss: 1.4782 - val_acc: 0.8820\n",
      "Epoch 55/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.0565 - acc: 0.9687 - val_loss: 1.4402 - val_acc: 0.8869\n",
      "Epoch 56/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 1.0370 - acc: 0.9697 - val_loss: 1.3923 - val_acc: 0.8942\n",
      "Epoch 57/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 1.0091 - acc: 0.9703 - val_loss: 1.4050 - val_acc: 0.8883\n",
      "Epoch 58/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.9894 - acc: 0.9701 - val_loss: 1.3921 - val_acc: 0.8859\n",
      "Epoch 59/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.9707 - acc: 0.9688 - val_loss: 1.3775 - val_acc: 0.8817\n",
      "Epoch 60/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.9395 - acc: 0.9734 - val_loss: 1.3236 - val_acc: 0.8902\n",
      "Epoch 61/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.9245 - acc: 0.9719 - val_loss: 1.3215 - val_acc: 0.8853\n",
      "Epoch 62/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.9172 - acc: 0.9680 - val_loss: 1.3467 - val_acc: 0.8838\n",
      "Epoch 63/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.8923 - acc: 0.9702 - val_loss: 1.2749 - val_acc: 0.8870\n",
      "Epoch 64/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.8740 - acc: 0.9710 - val_loss: 1.2634 - val_acc: 0.8827\n",
      "Epoch 65/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.8463 - acc: 0.9745 - val_loss: 1.2272 - val_acc: 0.8916\n",
      "Epoch 66/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.8318 - acc: 0.9738 - val_loss: 1.2523 - val_acc: 0.8811\n",
      "Epoch 67/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.8246 - acc: 0.9706 - val_loss: 1.2373 - val_acc: 0.8849\n",
      "Epoch 68/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.7968 - acc: 0.9744 - val_loss: 1.2763 - val_acc: 0.8807\n",
      "Epoch 69/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.7827 - acc: 0.9744 - val_loss: 1.2085 - val_acc: 0.8890\n",
      "Epoch 70/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.7592 - acc: 0.9778 - val_loss: 1.1658 - val_acc: 0.8892\n",
      "Epoch 71/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.7576 - acc: 0.9726 - val_loss: 1.1254 - val_acc: 0.8889\n",
      "Epoch 72/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.7598 - acc: 0.9676 - val_loss: 1.1879 - val_acc: 0.8819\n",
      "Epoch 73/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.7325 - acc: 0.9728 - val_loss: 1.1695 - val_acc: 0.8822\n",
      "Epoch 74/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.7082 - acc: 0.9760 - val_loss: 1.1347 - val_acc: 0.8915\n",
      "Epoch 75/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.6926 - acc: 0.9766 - val_loss: 1.1458 - val_acc: 0.8881\n",
      "Epoch 76/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.6777 - acc: 0.9776 - val_loss: 1.1376 - val_acc: 0.8854\n",
      "Epoch 77/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.6726 - acc: 0.9739 - val_loss: 1.1467 - val_acc: 0.8820\n",
      "Epoch 78/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.6692 - acc: 0.9730 - val_loss: 1.2000 - val_acc: 0.8686\n",
      "Epoch 79/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.6551 - acc: 0.9738 - val_loss: 1.0821 - val_acc: 0.8910\n",
      "Epoch 80/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.6389 - acc: 0.9751 - val_loss: 1.0371 - val_acc: 0.8916\n",
      "Epoch 81/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.6181 - acc: 0.9788 - val_loss: 1.0347 - val_acc: 0.8961\n",
      "Epoch 82/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.6121 - acc: 0.9779 - val_loss: 1.0904 - val_acc: 0.8841\n",
      "Epoch 83/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.6106 - acc: 0.9747 - val_loss: 1.0231 - val_acc: 0.8914\n",
      "Epoch 84/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5953 - acc: 0.9766 - val_loss: 1.0311 - val_acc: 0.8881\n",
      "Epoch 85/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.5778 - acc: 0.9793 - val_loss: 1.0402 - val_acc: 0.8882\n",
      "Epoch 86/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5713 - acc: 0.9783 - val_loss: 1.0626 - val_acc: 0.8795\n",
      "Epoch 87/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.5637 - acc: 0.9777 - val_loss: 1.0045 - val_acc: 0.8881\n",
      "Epoch 88/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5503 - acc: 0.9795 - val_loss: 0.9686 - val_acc: 0.8920\n",
      "Epoch 89/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5595 - acc: 0.9738 - val_loss: 1.0235 - val_acc: 0.8747\n",
      "Epoch 90/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5365 - acc: 0.9786 - val_loss: 1.0953 - val_acc: 0.8759\n",
      "Epoch 91/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5303 - acc: 0.9781 - val_loss: 1.0017 - val_acc: 0.8845\n",
      "Epoch 92/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.5273 - acc: 0.9766 - val_loss: 0.9110 - val_acc: 0.8915\n",
      "Epoch 93/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5113 - acc: 0.9794 - val_loss: 1.0719 - val_acc: 0.8782\n",
      "Epoch 94/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.5162 - acc: 0.9751 - val_loss: 0.9340 - val_acc: 0.8934\n",
      "Epoch 95/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.5020 - acc: 0.9785 - val_loss: 0.9465 - val_acc: 0.8927\n",
      "Epoch 96/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.4965 - acc: 0.9772 - val_loss: 0.9309 - val_acc: 0.8875\n",
      "Epoch 97/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.4900 - acc: 0.9781 - val_loss: 0.9573 - val_acc: 0.8854\n",
      "Epoch 98/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.4951 - acc: 0.9751 - val_loss: 0.9225 - val_acc: 0.8904\n",
      "Epoch 99/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.4808 - acc: 0.9777 - val_loss: 0.9055 - val_acc: 0.8844\n",
      "Epoch 100/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.4670 - acc: 0.9790 - val_loss: 0.8948 - val_acc: 0.8883\n",
      "Epoch 101/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.4304 - acc: 0.9914 - val_loss: 0.7940 - val_acc: 0.9143\n",
      "Epoch 102/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.4118 - acc: 0.9973 - val_loss: 0.7913 - val_acc: 0.9164\n",
      "Epoch 103/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.4074 - acc: 0.9985 - val_loss: 0.8044 - val_acc: 0.9182\n",
      "Epoch 104/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.4048 - acc: 0.9987 - val_loss: 0.8129 - val_acc: 0.9179\n",
      "Epoch 105/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.4023 - acc: 0.9992 - val_loss: 0.8212 - val_acc: 0.9196\n",
      "Epoch 106/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.4002 - acc: 0.9994 - val_loss: 0.8218 - val_acc: 0.9190\n",
      "Epoch 107/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3991 - acc: 0.9992 - val_loss: 0.8296 - val_acc: 0.9192\n",
      "Epoch 108/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3978 - acc: 0.9992 - val_loss: 0.8329 - val_acc: 0.9187\n",
      "Epoch 109/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3956 - acc: 0.9996 - val_loss: 0.8244 - val_acc: 0.9211\n",
      "Epoch 110/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3943 - acc: 0.9996 - val_loss: 0.8224 - val_acc: 0.9212\n",
      "Epoch 111/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3931 - acc: 0.9995 - val_loss: 0.8252 - val_acc: 0.9209\n",
      "Epoch 112/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3919 - acc: 0.9995 - val_loss: 0.8268 - val_acc: 0.9202\n",
      "Epoch 113/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3902 - acc: 0.9997 - val_loss: 0.8256 - val_acc: 0.9202\n",
      "Epoch 114/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3889 - acc: 0.9998 - val_loss: 0.8340 - val_acc: 0.9206\n",
      "Epoch 115/300\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.3879 - acc: 0.9995 - val_loss: 0.8365 - val_acc: 0.9207\n",
      "Epoch 116/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3863 - acc: 0.9998 - val_loss: 0.8292 - val_acc: 0.9216\n",
      "Epoch 117/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3851 - acc: 0.9997 - val_loss: 0.8345 - val_acc: 0.9197\n",
      "Epoch 118/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3839 - acc: 0.9997 - val_loss: 0.8334 - val_acc: 0.9206\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 309s 396ms/step - loss: 0.3826 - acc: 0.9998 - val_loss: 0.8339 - val_acc: 0.9207\n",
      "Epoch 120/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3814 - acc: 0.9997 - val_loss: 0.8384 - val_acc: 0.9199\n",
      "Epoch 121/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3807 - acc: 0.9996 - val_loss: 0.8347 - val_acc: 0.9213\n",
      "Epoch 122/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3789 - acc: 0.9998 - val_loss: 0.8386 - val_acc: 0.9209\n",
      "Epoch 123/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3776 - acc: 0.9998 - val_loss: 0.8431 - val_acc: 0.9198\n",
      "Epoch 124/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3765 - acc: 0.9998 - val_loss: 0.8343 - val_acc: 0.9219\n",
      "Epoch 125/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3750 - acc: 0.9999 - val_loss: 0.8330 - val_acc: 0.9211\n",
      "Epoch 126/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3742 - acc: 0.9997 - val_loss: 0.8288 - val_acc: 0.9236\n",
      "Epoch 127/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3733 - acc: 0.9997 - val_loss: 0.8164 - val_acc: 0.9239\n",
      "Epoch 128/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3718 - acc: 0.9998 - val_loss: 0.8210 - val_acc: 0.9242\n",
      "Epoch 129/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3705 - acc: 0.9998 - val_loss: 0.8202 - val_acc: 0.9239\n",
      "Epoch 130/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3694 - acc: 0.9999 - val_loss: 0.8282 - val_acc: 0.9230\n",
      "Epoch 131/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3680 - acc: 0.9998 - val_loss: 0.8241 - val_acc: 0.9237\n",
      "Epoch 132/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3669 - acc: 0.9998 - val_loss: 0.8248 - val_acc: 0.9238\n",
      "Epoch 133/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3659 - acc: 0.9998 - val_loss: 0.8199 - val_acc: 0.9245\n",
      "Epoch 134/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3646 - acc: 0.9999 - val_loss: 0.8193 - val_acc: 0.9241\n",
      "Epoch 135/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3636 - acc: 0.9997 - val_loss: 0.8194 - val_acc: 0.9248\n",
      "Epoch 136/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3624 - acc: 0.9998 - val_loss: 0.8207 - val_acc: 0.9244\n",
      "Epoch 137/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3612 - acc: 0.9999 - val_loss: 0.8228 - val_acc: 0.9234\n",
      "Epoch 138/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3604 - acc: 0.9997 - val_loss: 0.8213 - val_acc: 0.9217\n",
      "Epoch 139/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3593 - acc: 0.9998 - val_loss: 0.8146 - val_acc: 0.9237\n",
      "Epoch 140/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3577 - acc: 0.9999 - val_loss: 0.8099 - val_acc: 0.9237\n",
      "Epoch 141/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3567 - acc: 0.9999 - val_loss: 0.8110 - val_acc: 0.9238\n",
      "Epoch 142/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3558 - acc: 0.9997 - val_loss: 0.8100 - val_acc: 0.9244\n",
      "Epoch 143/300\n",
      "782/782 [==============================] - 308s 394ms/step - loss: 0.3545 - acc: 0.9999 - val_loss: 0.8149 - val_acc: 0.9237\n",
      "Epoch 144/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3533 - acc: 0.9998 - val_loss: 0.8155 - val_acc: 0.9242\n",
      "Epoch 145/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3522 - acc: 0.9999 - val_loss: 0.8135 - val_acc: 0.9245\n",
      "Epoch 146/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3511 - acc: 0.9999 - val_loss: 0.8098 - val_acc: 0.9230\n",
      "Epoch 147/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3501 - acc: 0.9998 - val_loss: 0.8064 - val_acc: 0.9250\n",
      "Epoch 148/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.3487 - acc: 1.0000 - val_loss: 0.8112 - val_acc: 0.9235\n",
      "Epoch 149/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3477 - acc: 1.0000 - val_loss: 0.8068 - val_acc: 0.9244\n",
      "Epoch 150/300\n",
      "782/782 [==============================] - 310s 396ms/step - loss: 0.3466 - acc: 0.9999 - val_loss: 0.8141 - val_acc: 0.9239\n",
      "Epoch 151/300\n",
      "782/782 [==============================] - 309s 395ms/step - loss: 0.3456 - acc: 0.9999 - val_loss: 0.8126 - val_acc: 0.9233\n",
      "Epoch 152/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3444 - acc: 0.9999 - val_loss: 0.8059 - val_acc: 0.9233\n",
      "Epoch 153/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.3434 - acc: 0.9999 - val_loss: 0.8096 - val_acc: 0.9236\n",
      "Epoch 154/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3423 - acc: 0.9999 - val_loss: 0.8094 - val_acc: 0.9238\n",
      "Epoch 155/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3414 - acc: 0.9999 - val_loss: 0.8056 - val_acc: 0.9244\n",
      "Epoch 156/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.3401 - acc: 1.0000 - val_loss: 0.8008 - val_acc: 0.9257\n",
      "Epoch 157/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3391 - acc: 1.0000 - val_loss: 0.7978 - val_acc: 0.9253\n",
      "Epoch 158/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3382 - acc: 0.9999 - val_loss: 0.8080 - val_acc: 0.9236\n",
      "Epoch 159/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3372 - acc: 0.9999 - val_loss: 0.8031 - val_acc: 0.9225\n",
      "Epoch 160/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3361 - acc: 0.9999 - val_loss: 0.8000 - val_acc: 0.9236\n",
      "Epoch 161/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3351 - acc: 0.9999 - val_loss: 0.7971 - val_acc: 0.9227\n",
      "Epoch 162/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3338 - acc: 1.0000 - val_loss: 0.7951 - val_acc: 0.9246\n",
      "Epoch 163/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3328 - acc: 1.0000 - val_loss: 0.8006 - val_acc: 0.9228\n",
      "Epoch 164/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3318 - acc: 0.9999 - val_loss: 0.7995 - val_acc: 0.9240\n",
      "Epoch 165/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3307 - acc: 1.0000 - val_loss: 0.8058 - val_acc: 0.9233\n",
      "Epoch 166/300\n",
      "782/782 [==============================] - 312s 398ms/step - loss: 0.3297 - acc: 0.9999 - val_loss: 0.8019 - val_acc: 0.9231\n",
      "Epoch 167/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3286 - acc: 1.0000 - val_loss: 0.8004 - val_acc: 0.9236\n",
      "Epoch 168/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3278 - acc: 0.9999 - val_loss: 0.7924 - val_acc: 0.9253\n",
      "Epoch 169/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3267 - acc: 0.9999 - val_loss: 0.7979 - val_acc: 0.9250\n",
      "Epoch 170/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3255 - acc: 0.9999 - val_loss: 0.7942 - val_acc: 0.9251\n",
      "Epoch 171/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3246 - acc: 0.9999 - val_loss: 0.7899 - val_acc: 0.9261\n",
      "Epoch 172/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.3235 - acc: 0.9999 - val_loss: 0.7888 - val_acc: 0.9244\n",
      "Epoch 173/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3226 - acc: 0.9999 - val_loss: 0.7892 - val_acc: 0.9254\n",
      "Epoch 174/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3215 - acc: 0.9999 - val_loss: 0.7889 - val_acc: 0.9248\n",
      "Epoch 175/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.3205 - acc: 1.0000 - val_loss: 0.7998 - val_acc: 0.9219\n",
      "Epoch 176/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3196 - acc: 0.9999 - val_loss: 0.7885 - val_acc: 0.9247\n",
      "Epoch 177/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3185 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.9251\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 312s 400ms/step - loss: 0.3175 - acc: 1.0000 - val_loss: 0.7954 - val_acc: 0.9227\n",
      "Epoch 179/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3166 - acc: 0.9999 - val_loss: 0.7887 - val_acc: 0.9242\n",
      "Epoch 180/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3157 - acc: 0.9999 - val_loss: 0.7855 - val_acc: 0.9243\n",
      "Epoch 181/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3145 - acc: 1.0000 - val_loss: 0.7928 - val_acc: 0.9244\n",
      "Epoch 182/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3136 - acc: 0.9999 - val_loss: 0.7797 - val_acc: 0.9254\n",
      "Epoch 183/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3125 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.9241\n",
      "Epoch 184/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3116 - acc: 0.9999 - val_loss: 0.7846 - val_acc: 0.9255\n",
      "Epoch 185/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.3106 - acc: 0.9999 - val_loss: 0.7828 - val_acc: 0.9248\n",
      "Epoch 186/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.3096 - acc: 1.0000 - val_loss: 0.7869 - val_acc: 0.9239\n",
      "Epoch 187/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3087 - acc: 0.9999 - val_loss: 0.7852 - val_acc: 0.9241\n",
      "Epoch 188/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3077 - acc: 0.9999 - val_loss: 0.7887 - val_acc: 0.9238\n",
      "Epoch 189/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.3067 - acc: 1.0000 - val_loss: 0.7797 - val_acc: 0.9244\n",
      "Epoch 190/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3057 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.9256\n",
      "Epoch 191/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3048 - acc: 1.0000 - val_loss: 0.7842 - val_acc: 0.9256\n",
      "Epoch 192/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3038 - acc: 1.0000 - val_loss: 0.7795 - val_acc: 0.9251\n",
      "Epoch 193/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3028 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.9248\n",
      "Epoch 194/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.3019 - acc: 1.0000 - val_loss: 0.7760 - val_acc: 0.9253\n",
      "Epoch 195/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.3010 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.9243\n",
      "Epoch 196/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.3001 - acc: 0.9999 - val_loss: 0.7736 - val_acc: 0.9260\n",
      "Epoch 197/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2991 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 0.9255\n",
      "Epoch 198/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2981 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.9250\n",
      "Epoch 199/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2972 - acc: 1.0000 - val_loss: 0.7751 - val_acc: 0.9246\n",
      "Epoch 200/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2964 - acc: 0.9999 - val_loss: 0.7789 - val_acc: 0.9249\n",
      "Epoch 201/300\n",
      "782/782 [==============================] - 314s 402ms/step - loss: 0.2958 - acc: 0.9999 - val_loss: 0.7763 - val_acc: 0.9249\n",
      "Epoch 202/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.2957 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.9241\n",
      "Epoch 203/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2957 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.9244\n",
      "Epoch 204/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2955 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 0.9252\n",
      "Epoch 205/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2955 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 0.9250\n",
      "Epoch 206/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2954 - acc: 1.0000 - val_loss: 0.7765 - val_acc: 0.9255\n",
      "Epoch 207/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2953 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.9242\n",
      "Epoch 208/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.2951 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.9256\n",
      "Epoch 209/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2951 - acc: 0.9999 - val_loss: 0.7716 - val_acc: 0.9249\n",
      "Epoch 210/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.2950 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.9247\n",
      "Epoch 211/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2949 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.9245\n",
      "Epoch 212/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2948 - acc: 1.0000 - val_loss: 0.7735 - val_acc: 0.9251\n",
      "Epoch 213/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2948 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.9257\n",
      "Epoch 214/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2948 - acc: 0.9999 - val_loss: 0.7727 - val_acc: 0.9242\n",
      "Epoch 215/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2946 - acc: 0.9999 - val_loss: 0.7711 - val_acc: 0.9250\n",
      "Epoch 216/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2945 - acc: 1.0000 - val_loss: 0.7778 - val_acc: 0.9250\n",
      "Epoch 217/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2944 - acc: 0.9999 - val_loss: 0.7743 - val_acc: 0.9246\n",
      "Epoch 218/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2943 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.9263\n",
      "Epoch 219/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2942 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.9249\n",
      "Epoch 220/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2941 - acc: 1.0000 - val_loss: 0.7677 - val_acc: 0.9259\n",
      "Epoch 221/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2940 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.9257\n",
      "Epoch 222/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2940 - acc: 0.9999 - val_loss: 0.7671 - val_acc: 0.9253\n",
      "Epoch 223/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2939 - acc: 1.0000 - val_loss: 0.7708 - val_acc: 0.9259\n",
      "Epoch 224/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2938 - acc: 1.0000 - val_loss: 0.7766 - val_acc: 0.9247\n",
      "Epoch 225/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2937 - acc: 0.9999 - val_loss: 0.7677 - val_acc: 0.9257\n",
      "Epoch 226/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.2936 - acc: 1.0000 - val_loss: 0.7646 - val_acc: 0.9257\n",
      "Epoch 227/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2936 - acc: 0.9999 - val_loss: 0.7737 - val_acc: 0.9243\n",
      "Epoch 228/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2935 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.9246\n",
      "Epoch 229/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2934 - acc: 1.0000 - val_loss: 0.7777 - val_acc: 0.9243\n",
      "Epoch 230/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2932 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.9246\n",
      "Epoch 231/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2932 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.9251\n",
      "Epoch 232/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2932 - acc: 0.9999 - val_loss: 0.7731 - val_acc: 0.9242\n",
      "Epoch 233/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2931 - acc: 1.0000 - val_loss: 0.7744 - val_acc: 0.9249\n",
      "Epoch 234/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2929 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.9260\n",
      "Epoch 235/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2928 - acc: 1.0000 - val_loss: 0.7688 - val_acc: 0.9260\n",
      "Epoch 236/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2929 - acc: 0.9999 - val_loss: 0.7684 - val_acc: 0.9260\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2927 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.9259\n",
      "Epoch 238/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2926 - acc: 0.9999 - val_loss: 0.7732 - val_acc: 0.9259\n",
      "Epoch 239/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2925 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.9261\n",
      "Epoch 240/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2924 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.9251\n",
      "Epoch 241/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2923 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.9259\n",
      "Epoch 242/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2923 - acc: 0.9999 - val_loss: 0.7667 - val_acc: 0.9260\n",
      "Epoch 243/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2922 - acc: 1.0000 - val_loss: 0.7710 - val_acc: 0.9266\n",
      "Epoch 244/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2921 - acc: 0.9999 - val_loss: 0.7688 - val_acc: 0.9256\n",
      "Epoch 245/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2920 - acc: 1.0000 - val_loss: 0.7738 - val_acc: 0.9255\n",
      "Epoch 246/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2919 - acc: 1.0000 - val_loss: 0.7676 - val_acc: 0.9268\n",
      "Epoch 247/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2919 - acc: 0.9999 - val_loss: 0.7660 - val_acc: 0.9264\n",
      "Epoch 248/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2918 - acc: 0.9999 - val_loss: 0.7640 - val_acc: 0.9258\n",
      "Epoch 249/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2916 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 0.9256\n",
      "Epoch 250/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2916 - acc: 0.9999 - val_loss: 0.7673 - val_acc: 0.9259\n",
      "Epoch 251/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2916 - acc: 0.9999 - val_loss: 0.7706 - val_acc: 0.9255\n",
      "Epoch 252/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2914 - acc: 0.9999 - val_loss: 0.7712 - val_acc: 0.9261\n",
      "Epoch 253/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2913 - acc: 1.0000 - val_loss: 0.7653 - val_acc: 0.9273\n",
      "Epoch 254/300\n",
      "782/782 [==============================] - 310s 397ms/step - loss: 0.2912 - acc: 0.9999 - val_loss: 0.7695 - val_acc: 0.9272\n",
      "Epoch 255/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2911 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.9259\n",
      "Epoch 256/300\n",
      "782/782 [==============================] - 311s 397ms/step - loss: 0.2910 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.9258\n",
      "Epoch 257/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2909 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9272\n",
      "Epoch 258/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2909 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.9260\n",
      "Epoch 259/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.2908 - acc: 1.0000 - val_loss: 0.7661 - val_acc: 0.9267\n",
      "Epoch 260/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.2908 - acc: 0.9999 - val_loss: 0.7671 - val_acc: 0.9261\n",
      "Epoch 261/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2906 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.9263\n",
      "Epoch 262/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.2905 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.9263\n",
      "Epoch 263/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2905 - acc: 0.9999 - val_loss: 0.7650 - val_acc: 0.9263\n",
      "Epoch 264/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2904 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.9258\n",
      "Epoch 265/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.2902 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.9246\n",
      "Epoch 266/300\n",
      "782/782 [==============================] - 314s 401ms/step - loss: 0.2902 - acc: 1.0000 - val_loss: 0.7629 - val_acc: 0.9262\n",
      "Epoch 267/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2901 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.9271\n",
      "Epoch 268/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2900 - acc: 1.0000 - val_loss: 0.7776 - val_acc: 0.9241\n",
      "Epoch 269/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2899 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.9246\n",
      "Epoch 270/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2899 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 0.9258\n",
      "Epoch 271/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2898 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.9267\n",
      "Epoch 272/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2896 - acc: 1.0000 - val_loss: 0.7613 - val_acc: 0.9268\n",
      "Epoch 273/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2897 - acc: 0.9999 - val_loss: 0.7677 - val_acc: 0.9259\n",
      "Epoch 274/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2895 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.9264\n",
      "Epoch 275/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2894 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.9263\n",
      "Epoch 276/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2893 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 0.9258\n",
      "Epoch 277/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2893 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.9248\n",
      "Epoch 278/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2891 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.9250\n",
      "Epoch 279/300\n",
      "782/782 [==============================] - 311s 398ms/step - loss: 0.2891 - acc: 1.0000 - val_loss: 0.7679 - val_acc: 0.9247\n",
      "Epoch 280/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2890 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 0.9251\n",
      "Epoch 281/300\n",
      "782/782 [==============================] - 312s 398ms/step - loss: 0.2889 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.9246\n",
      "Epoch 282/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2889 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.9270\n",
      "Epoch 283/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2887 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.9246\n",
      "Epoch 284/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2887 - acc: 1.0000 - val_loss: 0.7621 - val_acc: 0.9256\n",
      "Epoch 285/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2886 - acc: 1.0000 - val_loss: 0.7697 - val_acc: 0.9247\n",
      "Epoch 286/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2885 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.9254\n",
      "Epoch 287/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2884 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.9264\n",
      "Epoch 288/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2883 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.9257\n",
      "Epoch 289/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2882 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 0.9249\n",
      "Epoch 290/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2882 - acc: 0.9999 - val_loss: 0.7667 - val_acc: 0.9269\n",
      "Epoch 291/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2880 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.9257\n",
      "Epoch 292/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.9268\n",
      "Epoch 293/300\n",
      "782/782 [==============================] - 313s 401ms/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.7661 - val_acc: 0.9252\n",
      "Epoch 294/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2878 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.9259\n",
      "Epoch 295/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2877 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.9271\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2876 - acc: 1.0000 - val_loss: 0.7604 - val_acc: 0.9267\n",
      "Epoch 297/300\n",
      "782/782 [==============================] - 313s 400ms/step - loss: 0.2876 - acc: 1.0000 - val_loss: 0.7682 - val_acc: 0.9257\n",
      "Epoch 298/300\n",
      "782/782 [==============================] - 312s 400ms/step - loss: 0.2874 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9261\n",
      "Epoch 299/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2874 - acc: 1.0000 - val_loss: 0.7638 - val_acc: 0.9272\n",
      "Epoch 300/300\n",
      "782/782 [==============================] - 312s 399ms/step - loss: 0.2873 - acc: 1.0000 - val_loss: 0.7620 - val_acc: 0.9262\n"
     ]
    }
   ],
   "source": [
    "# set optimizer\n",
    "sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# set callback\n",
    "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
    "change_lr = LearningRateScheduler(scheduler)\n",
    "cbks = [change_lr,tb_cb]\n",
    "\n",
    "# set data augmentation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             width_shift_range=0.125,\n",
    "                             height_shift_range=0.125,\n",
    "                             fill_mode='constant',cval=0.)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# start training\n",
    "model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
    "                    steps_per_epoch=iterations,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=cbks,\n",
    "                    validation_data=(x_test, y_test))\n",
    "model.save('xception_he_wd_slim.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
